{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2020 Konstantin Yakovlev, Matthias Anderer\n",
    "\n",
    "   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "   you may not use this file except in compliance with the License.\n",
    "   You may obtain a copy of the License at\n",
    "\n",
    "       http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "   Unless required by applicable law or agreed to in writing, software\n",
    "   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "   See the License for the specific language governing permissions and\n",
    "   limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, time, warnings, pickle, psutil, random\n",
    "\n",
    "# custom imports\n",
    "from multiprocessing import Pool        # Multiprocess Runs\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Helpers\n",
    "#################################################################################\n",
    "## Seeder\n",
    "# :seed to make all processes deterministic     # type: int\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_MULTIPLIER = 0.90 # Set multiplier according to desired under-/overshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom loss function\n",
    "def custom_asymmetric_train(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    residual = (y_true - y_pred).astype(\"float\")\n",
    "    grad = np.where(residual < 0, -2 * residual, -2 * residual * LOSS_MULTIPLIER)\n",
    "    hess = np.where(residual < 0, 2, 2 * LOSS_MULTIPLIER)\n",
    "    return grad, hess\n",
    "\n",
    "# define custom evaluation metric\n",
    "def custom_asymmetric_valid(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    residual = (y_true - y_pred).astype(\"float\")\n",
    "    loss = np.where(residual < 0, (residual ** 2) , (residual ** 2) * LOSS_MULTIPLIER) \n",
    "    return \"custom_asymmetric_eval\", np.mean(loss), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Helper to load data by store ID\n",
    "#################################################################################\n",
    "# Read data\n",
    "def get_data_by_store(store):\n",
    "    \n",
    "    # Read and contact basic feature\n",
    "    df = pd.concat([pd.read_pickle(BASE),\n",
    "                    pd.read_pickle(PRICE).iloc[:,2:],\n",
    "                    pd.read_pickle(CALENDAR).iloc[:,2:]],\n",
    "                    axis=1)\n",
    "    \n",
    "    # Leave only relevant store\n",
    "    df = df[df['store_id']==store]\n",
    "    \n",
    "    ############\n",
    "    \n",
    "    # Create features list\n",
    "    features = [col for col in list(df) if col not in remove_features]\n",
    "    df = df[['id','d',TARGET]+features]\n",
    "    \n",
    "    # Skipping first n rows\n",
    "    df = df[df['d']>=START_TRAIN].reset_index(drop=True)\n",
    "    \n",
    "    return df, features\n",
    "\n",
    "# Recombine Test set after training\n",
    "def get_base_test():\n",
    "    base_test = pd.DataFrame()\n",
    "\n",
    "    for store_id in STORES_IDS:\n",
    "        temp_df = pd.read_pickle('test_'+store_id+'.pkl')\n",
    "        temp_df['store_id'] = store_id\n",
    "        base_test = pd.concat([base_test, temp_df]).reset_index(drop=True)\n",
    "    \n",
    "    return base_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Model params\n",
    "#################################################################################\n",
    "import lightgbm as lgb\n",
    "lgb_params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'tweedie',\n",
    "        'tweedie_variance_power': 1.1,\n",
    "        'metric':'rmse',\n",
    "        'n_jobs': -1,\n",
    "        'seed': 42,\n",
    "        'learning_rate': 0.2,\n",
    "        'bagging_fraction': 0.85,\n",
    "        'bagging_freq': 1, \n",
    "        'colsample_bytree': 0.85,\n",
    "        'colsample_bynode': 0.85,\n",
    "        #'min_data_per_leaf': 25,\n",
    "        #'num_leaves': 200,\n",
    "        'lambda_l1': 0.5,\n",
    "        'lambda_l2': 0.5\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CA_1',\n",
       " 'CA_2',\n",
       " 'CA_3',\n",
       " 'CA_4',\n",
       " 'TX_1',\n",
       " 'TX_2',\n",
       " 'TX_3',\n",
       " 'WI_1',\n",
       " 'WI_2',\n",
       " 'WI_3']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################### Vars\n",
    "#################################################################################\n",
    "VER = 1                          # Our model version\n",
    "SEED = 42                        # We want all things\n",
    "seed_everything(SEED)            # to be as deterministic \n",
    "lgb_params['seed'] = SEED        # as possible\n",
    "N_CORES = psutil.cpu_count()     # Available CPU cores\n",
    "\n",
    "\n",
    "#LIMITS and const\n",
    "TARGET      = 'sales'            # Our target\n",
    "START_TRAIN = 0                  # We can skip some rows (Nans/faster training)\n",
    "END_TRAIN   = 1913+28            # End day of our train set\n",
    "P_HORIZON   = 28                 # Prediction horizon\n",
    "USE_AUX     = False               # Use or not pretrained models\n",
    "\n",
    "#FEATURES to remove\n",
    "## These features lead to overfit\n",
    "## or values not present in test set\n",
    "remove_features = ['id','state_id','store_id',\n",
    "                   'date','wm_yr_wk','d',TARGET]\n",
    "\n",
    "#PATHS for Features\n",
    "ORIGINAL = 'C://Users//nkyam//Desktop//m5_forecast//'\n",
    "BASE     = 'C://Users//nkyam//Desktop//m5_forecast//grid_part_1.pkl'\n",
    "PRICE    = 'C://Users//nkyam//Desktop//m5_forecast//grid_part_2.pkl'\n",
    "CALENDAR = 'C://Users//nkyam//Desktop//m5_forecast//grid_part_3.pkl'\n",
    "\n",
    "#STORES ids\n",
    "STORES_IDS = pd.read_csv(ORIGINAL+'sales_train_validation.csv')['store_id']\n",
    "STORES_IDS = list(STORES_IDS.unique())\n",
    "STORES_IDS \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CA_1\n",
      "[LightGBM] [Info] Saving data to binary file train_data.bin\n",
      "[LightGBM] [Info] Load from binary file train_data.bin\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.119034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5643\n",
      "[LightGBM] [Info] Number of data points in the train set: 4751349, number of used features: 29\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 2.57778\tvalid_1's rmse: 2.23527\n",
      "[200]\ttraining's rmse: 2.48677\tvalid_1's rmse: 2.16952\n",
      "[300]\ttraining's rmse: 2.42343\tvalid_1's rmse: 2.13102\n",
      "[400]\ttraining's rmse: 2.37733\tvalid_1's rmse: 2.09395\n",
      "[500]\ttraining's rmse: 2.34\tvalid_1's rmse: 2.06527\n",
      "[600]\ttraining's rmse: 2.31166\tvalid_1's rmse: 2.04274\n",
      "[700]\ttraining's rmse: 2.28647\tvalid_1's rmse: 2.02632\n",
      "[800]\ttraining's rmse: 2.26514\tvalid_1's rmse: 2.01752\n",
      "[900]\ttraining's rmse: 2.24409\tvalid_1's rmse: 2.00647\n",
      "[1000]\ttraining's rmse: 2.22696\tvalid_1's rmse: 1.9992\n",
      "[1100]\ttraining's rmse: 2.20991\tvalid_1's rmse: 1.98886\n",
      "[1200]\ttraining's rmse: 2.19523\tvalid_1's rmse: 1.9775\n",
      "[1300]\ttraining's rmse: 2.18053\tvalid_1's rmse: 1.96663\n",
      "[1400]\ttraining's rmse: 2.16822\tvalid_1's rmse: 1.95559\n",
      "[1500]\ttraining's rmse: 2.15631\tvalid_1's rmse: 1.94851\n",
      "[1600]\ttraining's rmse: 2.14441\tvalid_1's rmse: 1.94224\n",
      "[1700]\ttraining's rmse: 2.13385\tvalid_1's rmse: 1.93561\n",
      "[1800]\ttraining's rmse: 2.12308\tvalid_1's rmse: 1.93208\n",
      "[1900]\ttraining's rmse: 2.1144\tvalid_1's rmse: 1.92536\n",
      "[2000]\ttraining's rmse: 2.10532\tvalid_1's rmse: 1.91911\n",
      "[2100]\ttraining's rmse: 2.09595\tvalid_1's rmse: 1.91115\n",
      "[2200]\ttraining's rmse: 2.087\tvalid_1's rmse: 1.90663\n",
      "[2300]\ttraining's rmse: 2.07814\tvalid_1's rmse: 1.89993\n",
      "[2400]\ttraining's rmse: 2.07041\tvalid_1's rmse: 1.89365\n",
      "[2500]\ttraining's rmse: 2.062\tvalid_1's rmse: 1.88759\n",
      "[2600]\ttraining's rmse: 2.05468\tvalid_1's rmse: 1.88227\n",
      "[2700]\ttraining's rmse: 2.04745\tvalid_1's rmse: 1.87778\n",
      "[2800]\ttraining's rmse: 2.04036\tvalid_1's rmse: 1.87263\n",
      "[2900]\ttraining's rmse: 2.03362\tvalid_1's rmse: 1.86967\n",
      "[3000]\ttraining's rmse: 2.02699\tvalid_1's rmse: 1.86677\n",
      "[3100]\ttraining's rmse: 2.02091\tvalid_1's rmse: 1.86171\n",
      "[3200]\ttraining's rmse: 2.01456\tvalid_1's rmse: 1.85798\n",
      "[3300]\ttraining's rmse: 2.00819\tvalid_1's rmse: 1.85329\n",
      "[3400]\ttraining's rmse: 2.00155\tvalid_1's rmse: 1.84918\n",
      "[3500]\ttraining's rmse: 1.9958\tvalid_1's rmse: 1.8437\n",
      "[3600]\ttraining's rmse: 1.98986\tvalid_1's rmse: 1.83987\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3600]\ttraining's rmse: 1.98986\tvalid_1's rmse: 1.83987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CA_2\n",
      "[LightGBM] [Warning] File train_data.bin exists, cannot save binary to it\n",
      "[LightGBM] [Info] Load from binary file train_data.bin\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.116246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5643\n",
      "[LightGBM] [Info] Number of data points in the train set: 4751349, number of used features: 29\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 2.57778\tvalid_1's rmse: 2.43308\n",
      "Early stopping, best iteration is:\n",
      "[83]\ttraining's rmse: 2.6008\tvalid_1's rmse: 2.42363\n",
      "Train CA_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] File train_data.bin exists, cannot save binary to it\n",
      "[LightGBM] [Info] Load from binary file train_data.bin\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.123310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5643\n",
      "[LightGBM] [Info] Number of data points in the train set: 4751349, number of used features: 29\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 2.57778\tvalid_1's rmse: 3.49268\n",
      "[200]\ttraining's rmse: 2.48677\tvalid_1's rmse: 3.46677\n",
      "[300]\ttraining's rmse: 2.42343\tvalid_1's rmse: 3.44184\n",
      "[400]\ttraining's rmse: 2.37733\tvalid_1's rmse: 3.43472\n",
      "[500]\ttraining's rmse: 2.34\tvalid_1's rmse: 3.42845\n",
      "[600]\ttraining's rmse: 2.31166\tvalid_1's rmse: 3.41688\n",
      "Early stopping, best iteration is:\n",
      "[611]\ttraining's rmse: 2.30843\tvalid_1's rmse: 3.41493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CA_4\n",
      "[LightGBM] [Warning] File train_data.bin exists, cannot save binary to it\n",
      "[LightGBM] [Info] Load from binary file train_data.bin\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.141086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5643\n",
      "[LightGBM] [Info] Number of data points in the train set: 4751349, number of used features: 29\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's rmse: 3.56613\tvalid_1's rmse: 1.62935\n",
      "Train TX_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] File train_data.bin exists, cannot save binary to it\n",
      "[LightGBM] [Info] Load from binary file train_data.bin\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.124042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5643\n",
      "[LightGBM] [Info] Number of data points in the train set: 4751349, number of used features: 29\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's rmse: 3.14795\tvalid_1's rmse: 2.37051\n",
      "Train TX_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] File train_data.bin exists, cannot save binary to it\n",
      "[LightGBM] [Info] Load from binary file train_data.bin\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.130841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5643\n",
      "[LightGBM] [Info] Number of data points in the train set: 4751349, number of used features: 29\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's rmse: 2.79519\tvalid_1's rmse: 2.69141\n",
      "Train TX_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] File train_data.bin exists, cannot save binary to it\n",
      "[LightGBM] [Info] Load from binary file train_data.bin\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.134444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5643\n",
      "[LightGBM] [Info] Number of data points in the train set: 4751349, number of used features: 29\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 2.57778\tvalid_1's rmse: 2.74856\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's rmse: 2.5841\tvalid_1's rmse: 2.74437\n",
      "Train WI_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] File train_data.bin exists, cannot save binary to it\n",
      "[LightGBM] [Info] Load from binary file train_data.bin\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.120714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5643\n",
      "[LightGBM] [Info] Number of data points in the train set: 4751349, number of used features: 29\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's rmse: 3.37752\tvalid_1's rmse: 2.30602\n",
      "Train WI_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] File train_data.bin exists, cannot save binary to it\n",
      "[LightGBM] [Info] Load from binary file train_data.bin\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.115224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5643\n",
      "[LightGBM] [Info] Number of data points in the train set: 4751349, number of used features: 29\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's rmse: 2.89318\tvalid_1's rmse: 4.54098\n",
      "Train WI_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] File train_data.bin exists, cannot save binary to it\n",
      "[LightGBM] [Info] Load from binary file train_data.bin\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.128375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5643\n",
      "[LightGBM] [Info] Number of data points in the train set: 4751349, number of used features: 29\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 2.57778\tvalid_1's rmse: 2.87879\n",
      "Early stopping, best iteration is:\n",
      "[86]\ttraining's rmse: 2.59734\tvalid_1's rmse: 2.87328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "########################### Train Models\n",
    "#################################################################################\n",
    "for store_id in STORES_IDS:\n",
    "    print('Train', store_id)\n",
    "    \n",
    "    # Get grid for current store\n",
    "    grid_df, features_columns = get_data_by_store(store_id)\n",
    "    \n",
    "    # Masks for \n",
    "    # Train (All data less than 1913)\n",
    "    # \"Validation\" (Last 28 days - not real validatio set)\n",
    "    # Test (All data greater than 1913 day, \n",
    "    #       with some gap for recursive features)\n",
    "    train_mask = grid_df['d']<=END_TRAIN\n",
    "    valid_mask = train_mask&(grid_df['d']>(END_TRAIN-P_HORIZON))\n",
    "    preds_mask = grid_df['d']>(END_TRAIN-100)\n",
    "    \n",
    "    # Apply masks and save lgb dataset as bin\n",
    "    # to reduce memory spikes during dtype convertations\n",
    "    # https://github.com/Microsoft/LightGBM/issues/1032\n",
    "    # \"To avoid any conversions, you should always use np.float32\"\n",
    "    # or save to bin before start training\n",
    "    # https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/discussion/53773\n",
    "    train_data = lgb.Dataset(grid_df[train_mask][features_columns], \n",
    "                       label=grid_df[train_mask][TARGET])\n",
    "    train_data.save_binary('train_data.bin')\n",
    "    train_data = lgb.Dataset('train_data.bin')\n",
    "    \n",
    "    valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], \n",
    "                       label=grid_df[valid_mask][TARGET])\n",
    "    \n",
    "    # Saving part of the dataset for later predictions\n",
    "    # Removing features that we need to calculate recursively \n",
    "    grid_df = grid_df[preds_mask].reset_index(drop=True)\n",
    "    keep_cols = [col for col in list(grid_df) if '_tmp_' not in col]\n",
    "    grid_df = grid_df[keep_cols]\n",
    "    grid_df.to_pickle('test_'+store_id+'.pkl')\n",
    "    del grid_df\n",
    "    \n",
    "    # Launch seeder again to make lgb training 100% deterministic\n",
    "    # with each \"code line\" np.random \"evolves\" \n",
    "    # so we need (may want) to \"reset\" it\n",
    "    seed_everything(SEED)\n",
    "    estimator = lgb.train(lgb_params,\n",
    "                          train_data,\n",
    "                          num_boost_round = 3600, \n",
    "                          early_stopping_rounds = 50, \n",
    "                          valid_sets = [train_data, valid_data],\n",
    "                          verbose_eval = 100,\n",
    "                          fobj = custom_asymmetric_train\n",
    "\n",
    "                          )\n",
    "    \n",
    "    # Save model - it's not real '.bin' but a pickle file\n",
    "    # estimator = lgb.Booster(model_file='model.txt')\n",
    "    # can only predict with the best iteration (or the saving iteration)\n",
    "    # pickle.dump gives us more flexibility\n",
    "    # like estimator.predict(TEST, num_iteration=100)\n",
    "    # num_iteration - number of iteration want to predict with, \n",
    "    # NULL or <= 0 means use best iteration\n",
    "    model_name = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin'\n",
    "    pickle.dump(estimator, open(model_name, 'wb'))\n",
    "\n",
    "    # Remove temporary files and objects \n",
    "    # to free some hdd space and ram memory\n",
    "    !rm train_data.bin\n",
    "    del train_data, valid_data, estimator\n",
    "    gc.collect()\n",
    "    \n",
    "    # \"Keep\" models features for predictions\n",
    "    MODEL_FEATURES = features_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict | Day: 1\n",
      "##########  0.03 min round |  0.03 min total |  35691.77 day sales |\n",
      "Predict | Day: 2\n",
      "##########  0.03 min round |  0.07 min total |  33119.12 day sales |\n",
      "Predict | Day: 3\n",
      "##########  0.03 min round |  0.10 min total |  33039.01 day sales |\n",
      "Predict | Day: 4\n",
      "##########  0.03 min round |  0.14 min total |  33069.33 day sales |\n",
      "Predict | Day: 5\n",
      "##########  0.03 min round |  0.17 min total |  36974.87 day sales |\n",
      "Predict | Day: 6\n",
      "##########  0.03 min round |  0.20 min total |  45805.86 day sales |\n",
      "Predict | Day: 7\n",
      "##########  0.03 min round |  0.24 min total |  46479.11 day sales |\n",
      "Predict | Day: 8\n",
      "##########  0.03 min round |  0.27 min total |  37955.44 day sales |\n",
      "Predict | Day: 9\n",
      "##########  0.03 min round |  0.31 min total |  33529.39 day sales |\n",
      "Predict | Day: 10\n",
      "##########  0.03 min round |  0.34 min total |  35400.60 day sales |\n",
      "Predict | Day: 11\n",
      "##########  0.03 min round |  0.37 min total |  34948.81 day sales |\n",
      "Predict | Day: 12\n",
      "##########  0.03 min round |  0.41 min total |  39755.39 day sales |\n",
      "Predict | Day: 13\n",
      "##########  0.03 min round |  0.44 min total |  47787.09 day sales |\n",
      "Predict | Day: 14\n",
      "##########  0.03 min round |  0.48 min total |  48346.71 day sales |\n",
      "Predict | Day: 15\n",
      "##########  0.03 min round |  0.51 min total |  37654.97 day sales |\n",
      "Predict | Day: 16\n",
      "##########  0.03 min round |  0.54 min total |  35002.38 day sales |\n",
      "Predict | Day: 17\n",
      "##########  0.03 min round |  0.58 min total |  34903.20 day sales |\n",
      "Predict | Day: 18\n",
      "##########  0.03 min round |  0.61 min total |  34937.58 day sales |\n",
      "Predict | Day: 19\n",
      "##########  0.03 min round |  0.65 min total |  38843.48 day sales |\n",
      "Predict | Day: 20\n",
      "##########  0.03 min round |  0.68 min total |  47036.17 day sales |\n",
      "Predict | Day: 21\n",
      "##########  0.03 min round |  0.71 min total |  47525.41 day sales |\n",
      "Predict | Day: 22\n",
      "##########  0.03 min round |  0.75 min total |  36577.53 day sales |\n",
      "Predict | Day: 23\n",
      "##########  0.03 min round |  0.78 min total |  34280.58 day sales |\n",
      "Predict | Day: 24\n",
      "##########  0.03 min round |  0.82 min total |  34138.77 day sales |\n",
      "Predict | Day: 25\n",
      "##########  0.03 min round |  0.85 min total |  34242.07 day sales |\n",
      "Predict | Day: 26\n",
      "##########  0.03 min round |  0.88 min total |  38220.28 day sales |\n",
      "Predict | Day: 27\n",
      "##########  0.03 min round |  0.92 min total |  47213.38 day sales |\n",
      "Predict | Day: 28\n",
      "##########  0.03 min round |  0.95 min total |  45581.88 day sales |\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>0.695455</td>\n",
       "      <td>0.627920</td>\n",
       "      <td>0.634909</td>\n",
       "      <td>0.638290</td>\n",
       "      <td>0.771773</td>\n",
       "      <td>0.874541</td>\n",
       "      <td>0.860751</td>\n",
       "      <td>0.704643</td>\n",
       "      <td>0.650626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790149</td>\n",
       "      <td>0.880365</td>\n",
       "      <td>0.871354</td>\n",
       "      <td>0.703043</td>\n",
       "      <td>0.643356</td>\n",
       "      <td>0.644853</td>\n",
       "      <td>0.652318</td>\n",
       "      <td>0.785640</td>\n",
       "      <td>0.900859</td>\n",
       "      <td>0.615358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>0.264270</td>\n",
       "      <td>0.200372</td>\n",
       "      <td>0.207361</td>\n",
       "      <td>0.206884</td>\n",
       "      <td>0.262328</td>\n",
       "      <td>0.369918</td>\n",
       "      <td>0.356127</td>\n",
       "      <td>0.285719</td>\n",
       "      <td>0.242217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285658</td>\n",
       "      <td>0.380697</td>\n",
       "      <td>0.379235</td>\n",
       "      <td>0.274786</td>\n",
       "      <td>0.218737</td>\n",
       "      <td>0.220234</td>\n",
       "      <td>0.227699</td>\n",
       "      <td>0.282982</td>\n",
       "      <td>0.403023</td>\n",
       "      <td>0.191609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
       "      <td>0.324104</td>\n",
       "      <td>0.260207</td>\n",
       "      <td>0.267196</td>\n",
       "      <td>0.266719</td>\n",
       "      <td>0.322163</td>\n",
       "      <td>0.429752</td>\n",
       "      <td>0.415962</td>\n",
       "      <td>0.345554</td>\n",
       "      <td>0.302052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351717</td>\n",
       "      <td>0.446755</td>\n",
       "      <td>0.445294</td>\n",
       "      <td>0.340845</td>\n",
       "      <td>0.284796</td>\n",
       "      <td>0.286293</td>\n",
       "      <td>0.293758</td>\n",
       "      <td>0.349041</td>\n",
       "      <td>0.469081</td>\n",
       "      <td>0.255989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
       "      <td>1.574922</td>\n",
       "      <td>1.458924</td>\n",
       "      <td>1.492131</td>\n",
       "      <td>1.495513</td>\n",
       "      <td>1.918454</td>\n",
       "      <td>2.863579</td>\n",
       "      <td>3.111008</td>\n",
       "      <td>2.428124</td>\n",
       "      <td>1.527630</td>\n",
       "      <td>...</td>\n",
       "      <td>1.931288</td>\n",
       "      <td>2.869235</td>\n",
       "      <td>3.105828</td>\n",
       "      <td>1.576592</td>\n",
       "      <td>1.463069</td>\n",
       "      <td>1.469940</td>\n",
       "      <td>1.472031</td>\n",
       "      <td>1.894811</td>\n",
       "      <td>2.852386</td>\n",
       "      <td>2.725282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
       "      <td>0.985829</td>\n",
       "      <td>0.921932</td>\n",
       "      <td>0.905528</td>\n",
       "      <td>0.905051</td>\n",
       "      <td>1.036905</td>\n",
       "      <td>1.328147</td>\n",
       "      <td>1.305458</td>\n",
       "      <td>0.959531</td>\n",
       "      <td>0.953728</td>\n",
       "      <td>...</td>\n",
       "      <td>1.178190</td>\n",
       "      <td>1.456880</td>\n",
       "      <td>1.446519</td>\n",
       "      <td>1.090907</td>\n",
       "      <td>1.034858</td>\n",
       "      <td>1.036355</td>\n",
       "      <td>1.043820</td>\n",
       "      <td>1.175514</td>\n",
       "      <td>1.479206</td>\n",
       "      <td>1.076534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30485</th>\n",
       "      <td>FOODS_3_823_WI_3_evaluation</td>\n",
       "      <td>0.640913</td>\n",
       "      <td>0.517282</td>\n",
       "      <td>0.517282</td>\n",
       "      <td>0.517282</td>\n",
       "      <td>0.655907</td>\n",
       "      <td>1.010777</td>\n",
       "      <td>1.010777</td>\n",
       "      <td>0.714033</td>\n",
       "      <td>0.517282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.759762</td>\n",
       "      <td>1.063393</td>\n",
       "      <td>1.054604</td>\n",
       "      <td>0.650408</td>\n",
       "      <td>0.550755</td>\n",
       "      <td>0.550755</td>\n",
       "      <td>0.550755</td>\n",
       "      <td>0.689381</td>\n",
       "      <td>1.044251</td>\n",
       "      <td>1.044251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30486</th>\n",
       "      <td>FOODS_3_824_WI_3_evaluation</td>\n",
       "      <td>0.687856</td>\n",
       "      <td>0.564225</td>\n",
       "      <td>0.564225</td>\n",
       "      <td>0.564225</td>\n",
       "      <td>0.790687</td>\n",
       "      <td>1.145558</td>\n",
       "      <td>1.145558</td>\n",
       "      <td>0.760976</td>\n",
       "      <td>0.564225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894542</td>\n",
       "      <td>1.198174</td>\n",
       "      <td>1.189385</td>\n",
       "      <td>0.697352</td>\n",
       "      <td>0.597699</td>\n",
       "      <td>0.597699</td>\n",
       "      <td>0.597699</td>\n",
       "      <td>0.824161</td>\n",
       "      <td>1.179031</td>\n",
       "      <td>1.179031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30487</th>\n",
       "      <td>FOODS_3_825_WI_3_evaluation</td>\n",
       "      <td>0.918917</td>\n",
       "      <td>0.795286</td>\n",
       "      <td>0.795286</td>\n",
       "      <td>0.795286</td>\n",
       "      <td>1.044729</td>\n",
       "      <td>1.399600</td>\n",
       "      <td>1.399600</td>\n",
       "      <td>0.992037</td>\n",
       "      <td>0.795286</td>\n",
       "      <td>...</td>\n",
       "      <td>1.158307</td>\n",
       "      <td>1.461939</td>\n",
       "      <td>1.453150</td>\n",
       "      <td>0.938136</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>1.087926</td>\n",
       "      <td>1.442796</td>\n",
       "      <td>1.442796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30488</th>\n",
       "      <td>FOODS_3_826_WI_3_evaluation</td>\n",
       "      <td>1.339918</td>\n",
       "      <td>1.229687</td>\n",
       "      <td>1.229687</td>\n",
       "      <td>1.229687</td>\n",
       "      <td>1.456802</td>\n",
       "      <td>1.965240</td>\n",
       "      <td>1.965240</td>\n",
       "      <td>1.426438</td>\n",
       "      <td>1.229687</td>\n",
       "      <td>...</td>\n",
       "      <td>1.547258</td>\n",
       "      <td>2.004456</td>\n",
       "      <td>1.995667</td>\n",
       "      <td>1.349414</td>\n",
       "      <td>1.249761</td>\n",
       "      <td>1.249761</td>\n",
       "      <td>1.249761</td>\n",
       "      <td>1.476876</td>\n",
       "      <td>1.985314</td>\n",
       "      <td>1.985314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30489</th>\n",
       "      <td>FOODS_3_827_WI_3_evaluation</td>\n",
       "      <td>1.418079</td>\n",
       "      <td>1.307848</td>\n",
       "      <td>1.307848</td>\n",
       "      <td>1.307848</td>\n",
       "      <td>1.534964</td>\n",
       "      <td>2.043401</td>\n",
       "      <td>2.043401</td>\n",
       "      <td>1.504599</td>\n",
       "      <td>1.307848</td>\n",
       "      <td>...</td>\n",
       "      <td>1.625419</td>\n",
       "      <td>2.082617</td>\n",
       "      <td>2.073828</td>\n",
       "      <td>1.427575</td>\n",
       "      <td>1.327922</td>\n",
       "      <td>1.327922</td>\n",
       "      <td>1.327922</td>\n",
       "      <td>1.555038</td>\n",
       "      <td>2.063475</td>\n",
       "      <td>2.063475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30490 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id        F1        F2        F3        F4  \\\n",
       "0      HOBBIES_1_001_CA_1_evaluation  0.695455  0.627920  0.634909  0.638290   \n",
       "1      HOBBIES_1_002_CA_1_evaluation  0.264270  0.200372  0.207361  0.206884   \n",
       "2      HOBBIES_1_003_CA_1_evaluation  0.324104  0.260207  0.267196  0.266719   \n",
       "3      HOBBIES_1_004_CA_1_evaluation  1.574922  1.458924  1.492131  1.495513   \n",
       "4      HOBBIES_1_005_CA_1_evaluation  0.985829  0.921932  0.905528  0.905051   \n",
       "...                              ...       ...       ...       ...       ...   \n",
       "30485    FOODS_3_823_WI_3_evaluation  0.640913  0.517282  0.517282  0.517282   \n",
       "30486    FOODS_3_824_WI_3_evaluation  0.687856  0.564225  0.564225  0.564225   \n",
       "30487    FOODS_3_825_WI_3_evaluation  0.918917  0.795286  0.795286  0.795286   \n",
       "30488    FOODS_3_826_WI_3_evaluation  1.339918  1.229687  1.229687  1.229687   \n",
       "30489    FOODS_3_827_WI_3_evaluation  1.418079  1.307848  1.307848  1.307848   \n",
       "\n",
       "             F5        F6        F7        F8        F9  ...       F19  \\\n",
       "0      0.771773  0.874541  0.860751  0.704643  0.650626  ...  0.790149   \n",
       "1      0.262328  0.369918  0.356127  0.285719  0.242217  ...  0.285658   \n",
       "2      0.322163  0.429752  0.415962  0.345554  0.302052  ...  0.351717   \n",
       "3      1.918454  2.863579  3.111008  2.428124  1.527630  ...  1.931288   \n",
       "4      1.036905  1.328147  1.305458  0.959531  0.953728  ...  1.178190   \n",
       "...         ...       ...       ...       ...       ...  ...       ...   \n",
       "30485  0.655907  1.010777  1.010777  0.714033  0.517282  ...  0.759762   \n",
       "30486  0.790687  1.145558  1.145558  0.760976  0.564225  ...  0.894542   \n",
       "30487  1.044729  1.399600  1.399600  0.992037  0.795286  ...  1.158307   \n",
       "30488  1.456802  1.965240  1.965240  1.426438  1.229687  ...  1.547258   \n",
       "30489  1.534964  2.043401  2.043401  1.504599  1.307848  ...  1.625419   \n",
       "\n",
       "            F20       F21       F22       F23       F24       F25       F26  \\\n",
       "0      0.880365  0.871354  0.703043  0.643356  0.644853  0.652318  0.785640   \n",
       "1      0.380697  0.379235  0.274786  0.218737  0.220234  0.227699  0.282982   \n",
       "2      0.446755  0.445294  0.340845  0.284796  0.286293  0.293758  0.349041   \n",
       "3      2.869235  3.105828  1.576592  1.463069  1.469940  1.472031  1.894811   \n",
       "4      1.456880  1.446519  1.090907  1.034858  1.036355  1.043820  1.175514   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "30485  1.063393  1.054604  0.650408  0.550755  0.550755  0.550755  0.689381   \n",
       "30486  1.198174  1.189385  0.697352  0.597699  0.597699  0.597699  0.824161   \n",
       "30487  1.461939  1.453150  0.938136  0.838483  0.838483  0.838483  1.087926   \n",
       "30488  2.004456  1.995667  1.349414  1.249761  1.249761  1.249761  1.476876   \n",
       "30489  2.082617  2.073828  1.427575  1.327922  1.327922  1.327922  1.555038   \n",
       "\n",
       "            F27       F28  \n",
       "0      0.900859  0.615358  \n",
       "1      0.403023  0.191609  \n",
       "2      0.469081  0.255989  \n",
       "3      2.852386  2.725282  \n",
       "4      1.479206  1.076534  \n",
       "...         ...       ...  \n",
       "30485  1.044251  1.044251  \n",
       "30486  1.179031  1.179031  \n",
       "30487  1.442796  1.442796  \n",
       "30488  1.985314  1.985314  \n",
       "30489  2.063475  2.063475  \n",
       "\n",
       "[30490 rows x 29 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################### Predict\n",
    "#################################################################################\n",
    "\n",
    "# Create Dummy DataFrame to store predictions\n",
    "all_preds = pd.DataFrame()\n",
    "\n",
    "# Join back the Test dataset with \n",
    "# a small part of the training data \n",
    "# to make recursive features\n",
    "base_test = get_base_test()\n",
    "\n",
    "# Timer to measure predictions time \n",
    "main_time = time.time()\n",
    "\n",
    "# Loop over each prediction day\n",
    "# As rolling lags are the most timeconsuming\n",
    "# we will calculate it for whole day\n",
    "for PREDICT_DAY in range(1,29):    \n",
    "    print('Predict | Day:', PREDICT_DAY)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Make temporary grid to calculate rolling lags\n",
    "    grid_df = base_test.copy()\n",
    "        \n",
    "    for store_id in STORES_IDS:\n",
    "        \n",
    "        # Read all our models and make predictions\n",
    "        # for each day/store pairs\n",
    "        model_path = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin' \n",
    "        if USE_AUX:\n",
    "            model_path = AUX_MODELS + model_path\n",
    "        \n",
    "        estimator = pickle.load(open(model_path, 'rb'))\n",
    "        \n",
    "        day_mask = base_test['d']==(END_TRAIN+PREDICT_DAY)\n",
    "        store_mask = base_test['store_id']==store_id\n",
    "        \n",
    "        mask = (day_mask)&(store_mask)\n",
    "        base_test[TARGET][mask] = estimator.predict(grid_df[mask][MODEL_FEATURES])\n",
    "    \n",
    "    # Make good column naming and add \n",
    "    # to all_preds DataFrame\n",
    "    temp_df = base_test[day_mask][['id',TARGET]]\n",
    "    temp_df.columns = ['id','F'+str(PREDICT_DAY)]\n",
    "    if 'id' in list(all_preds):\n",
    "        all_preds = all_preds.merge(temp_df, on=['id'], how='left')\n",
    "    else:\n",
    "        all_preds = temp_df.copy()\n",
    "        \n",
    "    print('#'*10, ' %0.2f min round |' % ((time.time() - start_time) / 60),\n",
    "                  ' %0.2f min total |' % ((time.time() - main_time) / 60),\n",
    "                  ' %0.2f day sales |' % (temp_df['F'+str(PREDICT_DAY)].sum()))\n",
    "    del temp_df\n",
    "    \n",
    "all_preds = all_preds.reset_index(drop=True)\n",
    "all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Export\n",
    "#################################################################################\n",
    "# Reading competition sample submission and\n",
    "# merging our predictions\n",
    "# As we have predictions only for \"_validation\" data\n",
    "# we need to do fillna() for \"_evaluation\" items\n",
    "submission = pd.read_csv(ORIGINAL+'sample_submission.csv')[['id']]\n",
    "submission = submission.merge(all_preds, on=['id'], how='left').fillna(0)\n",
    "submission.to_csv('submission_v'+str(VER)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
